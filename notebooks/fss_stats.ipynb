{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook accompanying the paper\n",
    "\n",
    "Note that this notebook requires installing: pysteps, matplotlib, cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr\n",
    "from pysteps.verification.spatialscores import fss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HOME = Path(os.getcwd()).parents[0]\n",
    "\n",
    "sys.path.insert(1, str(HOME))\n",
    "\n",
    "from fssim.scoring import get_convoluted_fractions, calculate_fractions_SSIM, calculate_correlation\n",
    "\n",
    "latitude_range = np.arange(-11.95, 15.95, 0.1)\n",
    "longitude_range = np.arange(25.05, 49.05, 0.1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of correlation and FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('examples.pkl', 'rb') as ifh:\n",
    "    examples = pickle.load(ifh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_letters = string.ascii_lowercase\n",
    "\n",
    "plt.rcParams.update({'font.size': 5})\n",
    "plt.rcParams.update({\n",
    "\"text.usetex\": True,\n",
    "\"font.family\": \"sans-serif\",\n",
    "\"font.sans-serif\": [\"Helvetica\"]})\n",
    "\n",
    "\n",
    "threshold = 0.1\n",
    "n_range = range(0,250)\n",
    "window_width_range = [2*n+1 for n in n_range]\n",
    "linewidth=1\n",
    "year_of_data = 2019\n",
    "\n",
    "examples_chunks = [examples[0:2], examples[2:4], examples[4:]]\n",
    "\n",
    "\n",
    "for chunk_number, example_chunk in enumerate(examples_chunks):\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(len(example_chunk),3, figsize=(6.5,2*len(example_chunk)), constrained_layout=True)\n",
    "    # fig.tight_layout()\n",
    "\n",
    "    for ex_no, example in enumerate(example_chunk):\n",
    "\n",
    "        \n",
    "        \n",
    "        hr_start = example['hr_start']\n",
    "        hr_end = example['hr_end']\n",
    "        day=example['day']\n",
    "        month=example['month']\n",
    "        \n",
    "        mode = 'constant'\n",
    "\n",
    "        corr_results= {}\n",
    "\n",
    "        X_o = example['obs']\n",
    "        X_f = example['forecast']\n",
    "\n",
    "        # Evaluate mean of truth array and make sure fcst_array has the same mean.\n",
    "\n",
    "        f0 = (X_o > 0.1).mean()\n",
    "        fss_results = [fss(X_o=X_o[:,:], X_f=X_f[:,:], thr=threshold, \n",
    "                        scale=2*n+1) for n in n_range] \n",
    "        \n",
    "        fssim_bias_beta=3.0\n",
    "        fssim_rhomin=0.1\n",
    "\n",
    "        fssim_results = [calculate_fractions_SSIM(X_o=X_o[:,:], X_f=X_f[:,:], thr=threshold, \n",
    "                        scale=2*n+1, max_bias=fssim_bias_beta, rho_min=fssim_rhomin, mode=mode) for n in n_range]\n",
    "        fssim_scores = [item[0] for item in fssim_results]\n",
    "        fssim_thresholds = [item[1] for item in fssim_results]\n",
    "\n",
    "\n",
    "        S_f = [get_convoluted_fractions(array=X_f[:,:], threshold=threshold, scale=2*n+1, mode=mode) for n in n_range]\n",
    "        S_o = [get_convoluted_fractions(array=X_o[:,:], threshold=threshold, scale=2*n+1, mode=mode) for n in n_range]\n",
    "\n",
    "        fcst_mu = [item.mean() for item in S_f]\n",
    "        fcst_sigma = [item.std() for item in S_f]\n",
    "\n",
    "        obs_mu = [item.mean() for item in S_o]\n",
    "        obs_sigma = [item.std() for item in S_o]\n",
    "\n",
    "\n",
    "        rho = [pearsonr(S_f[ii].flatten(), S_o[ii].flatten()).statistic for ii in range(len(n_range))]\n",
    "        mu_bias = [2*obs_mu[ii]*fcst_mu[ii] / (obs_mu[ii]**2 + fcst_mu[ii]**2) for ii in range(len(n_range))]\n",
    "        sigma_bias = [2*obs_sigma[ii]*fcst_sigma[ii] / (obs_sigma[ii]**2 + fcst_sigma[ii]**2) for ii in range(len(n_range))]\n",
    "    \n",
    "        fig2, ax = plt.subplots(1, 1, figsize=(3.5,3))\n",
    "        \n",
    "        ax.plot(window_width_range, rho, label=r'$\\rho_n$', linewidth=linewidth, color='b', linestyle='dotted')\n",
    "        ax.plot(window_width_range, fss_results, label=r'$\\textrm{FSS}$', linewidth=linewidth, color='k')\n",
    "\n",
    "        fcst_fss = fss_results\n",
    "\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_xlabel(r'\\textrm{Neighbourhood width (pixels)}')\n",
    "        ax.set_ylim(min(min(rho) - 0.01, 0),1)\n",
    "        ax.hlines(y=0.5 + f0*0.5, xmin=min(window_width_range), xmax=max(window_width_range), linestyles='dashed', colors='k', linewidth=linewidth)\n",
    "        ax.set_xticks([1,200,400])\n",
    "      \n",
    "        plt.savefig(f'plots/fss_Ln_{month}_{day}_{year_of_data}_hr{hr_start}-{hr_end}_thr{threshold}_mode-{mode}.pdf', format='pdf', bbox_inches = 'tight')\n",
    "\n",
    "        axs[ex_no, 0].plot(window_width_range, fssim_scores, label=r'$\\textrm{F-SSIM}$', linewidth=linewidth, color='k', linestyle='-')\n",
    "        axs[ex_no, 0].plot(window_width_range, fss_results, label=r'$\\textrm{FSS}$', linewidth=linewidth, color='r')\n",
    "        axs[ex_no, 0].plot(window_width_range, fssim_thresholds, linewidth=linewidth, linestyle='--')\n",
    "\n",
    "        axs[ex_no, 0].legend(loc='lower right', ncol=2)\n",
    "        axs[ex_no, 0].set_xlabel(r'\\textrm{Neighbourhood width (pixels)}')\n",
    "        axs[ex_no, 0].set_ylim(0,1)\n",
    "        axs[ex_no, 0].set_xlim(0,max(window_width_range))\n",
    "        axs[ex_no, 0].set_xticks([1,100,200,300,400,500])\n",
    "        axs[ex_no, 0].set_title(f'({all_letters[ex_no * 3]})')\n",
    "\n",
    "        # F-SSIM plots\n",
    "        axs[ex_no, 1].plot(window_width_range,rho, label=r'$\\rho_n$', linewidth=linewidth, color='b', linestyle='dotted')\n",
    "        axs[ex_no, 1].plot(window_width_range,mu_bias, label=r'$\\frac{2\\mu_o \\mu_f}{ (\\mu^2_o + \\mu^2_f)}$', linewidth=linewidth, color='k', linestyle='--')\n",
    "        axs[ex_no, 1].plot(window_width_range,sigma_bias, label=r'$\\frac{2\\sigma_o \\sigma_f }{ (\\sigma^2_o + \\sigma^2_f)}$', linewidth=linewidth, color='r', linestyle='-.')\n",
    "\n",
    "        if (chunk_number ==0 and ex_no ==1) or (chunk_number == 2):\n",
    "            ncol=1\n",
    "        else:\n",
    "            ncol = 2\n",
    "        axs[ex_no, 1].legend(loc='lower right', ncol=ncol)\n",
    "        axs[ex_no, 1].set_ylim(min(min(rho),0),1)\n",
    "        axs[ex_no, 1].set_xlim(0,max(window_width_range))\n",
    "        axs[ex_no, 1].set_xticks([1,100,200,300,400,500])\n",
    "        axs[ex_no, 1].set_xlabel(r'\\textrm{Neighbourhood width (pixels)}')\n",
    "        axs[ex_no, 1].set_title(f'({all_letters[ex_no * 3 + 1]})')\n",
    "\n",
    "        corr, p = calculate_correlation(X_o, X_f, threshold=threshold,\n",
    "                                    window_range=[1,2,3,4,5, 7, 10, 15, 20, 25, 30, 40, 50, 60, 80, 100, 150, 200, 230])\n",
    "        obs_mean = 0.5*(np.array(list(corr['t_tn_row'].values())) + np.array(list(corr['t_tn_col'].values())))\n",
    "        fcst_mean = 0.5*(np.array(list(corr['f_fn_row'].values())) + np.array(list(corr['f_fn_col'].values())))\n",
    "\n",
    "        axs[ex_no, 2].plot(corr['t_tn_row'].keys(), obs_mean, linewidth=linewidth, color='k', linestyle='-', label='Observations (IMERG)')\n",
    "        axs[ex_no, 2].plot(corr['t_tn_row'].keys(), fcst_mean, linewidth=linewidth, color='k', linestyle='--', label='Forecast')\n",
    "        axs[ex_no, 2].set_xlabel(r'\\textrm{Separation (pixels)}')\n",
    "        axs[ex_no, 2].set_ylabel(r'\\textrm{Averaged correlation}')\n",
    "        axs[ex_no, 2].legend(loc='upper right')\n",
    "        axs[ex_no, 2].set_xticks([1,100,200])\n",
    "        axs[ex_no, 2].set_title(f'({all_letters[ex_no * 3 + 2]})')\n",
    "\n",
    "        plt.figure(fig)\n",
    "        plt.savefig(f'plots/fssim_fig_{chunk_number}.pdf', format='pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 0.1\n",
    "n_range = range(1,250)\n",
    "\n",
    "def fss_lower_bound(mu_obs, mu_f, sigma_obs, sigma_f):\n",
    "    return (2*mu_obs*mu_f)/(mu_obs**2 + mu_f**2 + sigma_obs**2 + sigma_f**2)\n",
    "\n",
    "def fss_correlation(fss, mu_obs, mu_f, sigma_obs, sigma_f):\n",
    "    lb = fss_lower_bound(mu_obs, mu_f, sigma_obs, sigma_f)\n",
    "    return (fss - lb) * (mu_obs**2 + mu_f**2 + sigma_obs**2 + sigma_f**2) / (2*sigma_f*sigma_obs)\n",
    "\n",
    "def theoretical_fss(mu_obs, mu_f, sigma_obs, sigma_f, rho):\n",
    "    \n",
    "    lb = fss_lower_bound(mu_obs, mu_f, sigma_obs, sigma_f)\n",
    "    \n",
    "    return lb  + 2 *(rho * sigma_f * sigma_obs) / (mu_obs**2 + mu_f**2 + sigma_obs**2 + sigma_f**2)\n",
    "\n",
    "\n",
    "n_random_samples = 20\n",
    "n_range = np.arange(250)\n",
    "window_width_range = [2*n+1 for n in n_range]\n",
    "threshold=0.1\n",
    "\n",
    "mode = 'constant'\n",
    "\n",
    "corr_results= {}\n",
    "\n",
    "with open('fss_bias_data_2019_3_1.pkl', 'rb') as ifh:\n",
    "    X_o = pickle.load(ifh)\n",
    "\n",
    "S_o = [get_convoluted_fractions(array=X_o[:,:], threshold=threshold, scale=2*n+1, mode='constant') for n in n_range]\n",
    "\n",
    "obs_mu = [item.mean() for item in S_o]\n",
    "obs_sigma = [item.std() for item in S_o]\n",
    "\n",
    "bias_vals_mu = np.arange(0,3,1.0)\n",
    "bias_vals_sigma = np.arange(-0.6, 0, 0.2)\n",
    "theoretical_fss_vals_mu = []\n",
    "\n",
    "for n, bv in enumerate(bias_vals_mu):\n",
    "    \n",
    "    rho_crit=0.1\n",
    "    \n",
    "    rand_mu = [(1+bv)*item for item in obs_mu]\n",
    "    rand_sigma = [item for item in obs_sigma]\n",
    "\n",
    "    theoretical_fss_vals_mu.append([theoretical_fss(obs_mu[n], rand_mu[n], obs_sigma[n], rand_sigma[n], rho_crit) for n in range(len(n_range))])\n",
    "    \n",
    "theoretical_fss_vals_sigma = []\n",
    "for n, bv in enumerate(bias_vals_sigma):\n",
    "    \n",
    "    rho_crit=0.3\n",
    "    \n",
    "    rand_mu = [item for item in obs_mu]\n",
    "    rand_sigma = [(1+bv)*item for item in obs_sigma]\n",
    "\n",
    "    theoretical_fss_vals_sigma.append([theoretical_fss(obs_mu[n], rand_mu[n], obs_sigma[n], rand_sigma[n], rho_crit) for n in range(len(n_range))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(6,3))\n",
    "\n",
    "linestyles=['-', '--',':']\n",
    "\n",
    "\n",
    "for m, bv in enumerate(bias_vals_mu):\n",
    "    \n",
    "    axs[0].plot(window_width_range, theoretical_fss_vals_mu[m], label=r'$\\beta_\\mu$' + f'= {bv:0.1f}', color='k', linestyle=linestyles[m])\n",
    "    \n",
    "axs[0].set_xlabel('Neighbourhood width (pixels)')\n",
    "\n",
    "# ax.plot(window_range, theoretical_random_fss_vals, label=f'rand_th')\n",
    "axs[0].set_ylim([0,1.01])\n",
    "axs[0].set_xticks([1,200,400])\n",
    "axs[0].legend()\n",
    "\n",
    "for m, bv in enumerate(bias_vals_sigma):\n",
    "    \n",
    "    axs[1].plot(window_width_range, theoretical_fss_vals_sigma[m], label=r'$\\beta_\\sigma$' + f'= {bv:0.1f}', color='k', linestyle=linestyles[m])\n",
    "    \n",
    "axs[1].set_xlabel('Neighbourhood width (pixels)')\n",
    "\n",
    "# ax.plot(window_range, theoretical_random_fss_vals, label=f'rand_th')\n",
    "axs[1].set_ylim([0,1.01])\n",
    "axs[1].legend(loc='lower right')\n",
    "axs[1].set_xticks([1,200,400])\n",
    "\n",
    "plt.savefig('plots/bias.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colors\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "lake_feature = cfeature.NaturalEarthFeature(\n",
    "    'physical', 'lakes',\n",
    "    cfeature.auto_scaler, edgecolor='black', facecolor='never')\n",
    "\n",
    "def plot_contourf( data, title, lon_range, lat_range, ax=None, value_range=None,\n",
    "                  cmap='Reds', extend: str='both'):\n",
    "    \n",
    "    \n",
    "    if value_range is not None:\n",
    "        im = ax.contourf(lon_range, lat_range, data, transform=ccrs.PlateCarree(),\n",
    "                            cmap=cmap, \n",
    "                            levels=value_range, norm=colors.Normalize(min(value_range), max(value_range)),\n",
    "                            extend=extend)\n",
    "    else:\n",
    "\n",
    "        im = ax.contourf(lon_range, lat_range, data, transform=ccrs.PlateCarree(),\n",
    "                    cmap=cmap, \n",
    "                    extend=extend)\n",
    "\n",
    "    ax.coastlines(resolution='10m', color='black', linewidth=0.4)\n",
    "    \n",
    "    ax.add_feature(lake_feature, alpha=0.4)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('asdf')\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "from src.scoring import get_convoluted_fractions\n",
    "from src.utils import plot_contourf\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colorbar, gridspec\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "n_vals = [0, 10, 100]\n",
    "\n",
    "for example in examples[1:2]:\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(6.5, 4))\n",
    "    gs = gridspec.GridSpec(3, len(n_vals), figure=fig, \n",
    "                        height_ratios=[1, 1] + [0.05],\n",
    "                        wspace=0.005)  \n",
    "\n",
    "    month = example['month']\n",
    "    day = example['day']\n",
    "    hr_start = example['hr_start']\n",
    "    hr_end = example['hr_end']\n",
    "    year_of_data = 2019\n",
    "    threshold = 0.1\n",
    "    mode = 'constant'\n",
    "    print(month, day, year_of_data)\n",
    "\n",
    "\n",
    "    for m, n_val in enumerate(n_vals):\n",
    "\n",
    "        ax_obs = fig.add_subplot(gs[0, m], projection = ccrs.PlateCarree())\n",
    "        ax_fcst = fig.add_subplot(gs[1, m], projection = ccrs.PlateCarree())\n",
    "        \n",
    "        width = 2*n_val + 1\n",
    "\n",
    "        smoothed_obs = get_convoluted_fractions(example['obs'], threshold=threshold, scale=width, mode=mode)\n",
    "        smoothed_fcst = get_convoluted_fractions(example['forecast'], threshold=threshold, scale=width, mode=mode)\n",
    "        \n",
    "        max_val = np.round(max(smoothed_obs[0,:,:].max(), smoothed_fcst[0,:,:].max()), 2)\n",
    "\n",
    "        if max_val > 0.9:\n",
    "            step_size = 0.2\n",
    "        elif max_val < 0.2:\n",
    "            step_size = 0.05\n",
    "        else:\n",
    "            step_size = 0.1\n",
    "\n",
    "        val_range = [item for item in  np.arange(0,1+step_size,step_size/4) if item < max_val]\n",
    "        if val_range[-1] != 1:\n",
    "            val_range = val_range + [np.arange(0,1+step_size,step_size/4)[len(val_range)]]\n",
    "\n",
    "        ticks = [item for item in  np.arange(0,val_range[-1]+0.1,step_size) ]\n",
    "\n",
    "        smoothed_obs[0,:,:][smoothed_obs[0,:,:] ==0] = -0.1\n",
    "        smoothed_fcst[0,:,:][smoothed_fcst[0,:,:] ==0] = -0.1\n",
    "        im0 = plot_contourf(ax=ax_obs, data=smoothed_obs[0,:,:], title=f'Width={width}', lon_range=longitude_range, \n",
    "                            lat_range=latitude_range, cmap='Blues', value_range=val_range, extend='neither')\n",
    "        im1 = plot_contourf(ax=ax_fcst, data=smoothed_fcst[0,:,:], title=f'Width={width}', lon_range=longitude_range, lat_range=latitude_range, \n",
    "                            cmap='Blues', value_range=val_range, extend='neither')\n",
    "\n",
    "        cbar_ax = fig.add_subplot(gs[-1, m])\n",
    "        cb0 = fig.colorbar(im0, cax=cbar_ax, orientation='horizontal', shrink = 0.2, aspect=8, ticks=ticks)\n",
    "    \n",
    "plt.savefig(f'plots/blurring_{month}_{day}_{year_of_data}_hr{hr_start}-{hr_end}_thr{threshold}_mode{mode}.pdf', format='pdf', bbox_inches = 'tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38aeaf5f44d8d0d88b260b9ca791ce740e9ae0a80ffa18a97a3cb73507d0bb25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
